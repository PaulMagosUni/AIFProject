{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9170c3bc",
   "metadata": {},
   "source": [
    "# Project Report - \"Magoni Adventure\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "### Welcome to the most thrilling project report you'll read today! Our project, codenamed <strong>\"The Magoni Adventure\"</strong> is a masterpiece in the making. We hope you enjoy reading it as much as we enjoyed writing it.\n",
    "#### We are <font color='fb9f89'><strong>Paul Magos</strong></font> & <font color='fb9f89'><strong>Stefano Zanoni</strong></font>, and we're here to take you on a journey of algorithms comparison (with some strange approaches) in the field of <font color='green'><strong>Efficiently Solving Mazes in Minihack</strong></font>."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1d2793b28100c28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Technologies Used\n",
    "We harnessed the power of many libraries to create our project.\n",
    "Before we begin, let's make sure you have everything you need to follow along. Here's a list of used libraries:\n",
    "- <font color='red'><strong>numpy</strong></font>\n",
    "- <font color='red'><strong>matplotlib</strong></font>\n",
    "- <font color='red'><strong>minihack</strong></font>\n",
    "- <font color='red'><strong>scipy</strong></font>\n",
    "- <font color='red'><strong>nethack</strong></font>\n",
    "- <font color='red'><strong>nle</strong></font>\n",
    "- <font color='red'><strong>keras</strong></font>\n",
    "- <font color='red'><strong>gym</strong></font>\n",
    "- <font color='red'><strong>tensorflow</strong></font>\n",
    "- <font color='red'><strong>pytorch</strong></font>\n",
    "- <font color='red'><strong>pickle</strong></font>\n",
    "- <font color='red'><strong>Pillow</strong></font>\n",
    "- <font color='red'><strong>imageio</strong></font>\n",
    "- <font color='red'><strong>pandas</strong></font>\n",
    "\n",
    "And here's a list of the other optional libraries:\n",
    "- <font color='gray'><strong>wandb</strong></font> (not necessary, but useful if you want to perform again the experiments)\n",
    "\n",
    "### Uncomment the following cell if you need to install the libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2fdbee7e488b5d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# % pip install wandb\n",
    "# % pip install numpy\n",
    "# % pip install matplotlib\n",
    "# % pip install scipy\n",
    "# % pip install gym\n",
    "# % pip install nethack\n",
    "# % pip install minihack\n",
    "# % pip install nle\n",
    "# % pip install keras\n",
    "# % pip install tensorflow\n",
    "# % pip install pytorch\n",
    "# % pip install Pillow\n",
    "# % pip install imageio\n",
    "# % pip install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:31:13.430224Z",
     "start_time": "2024-01-24T23:31:13.385065Z"
    }
   },
   "id": "5d7d46888a37a485",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project Structure\n",
    "Here's a quick overview of the project structure. We've included a brief description of each file to help you navigate:\n",
    "- <font><strong>nextdataAI</strong></font> The root folder of the project:\n",
    "    - <strong>algorithms</strong> This folder contains all the algorithms that we implemented <br>\n",
    "        <em>Algorithm.py</em> Is the superclass of all algorithms, which creates the env, sets the seed so that all are working on the same maze, and also contains the method to run the algorithm. \n",
    "        - Standard:\n",
    "            - <em>AStart</em>, <em>Greedy</em>, <em>Random</em>, <em>Genetic</em>, <em>Dijkstra</em>, <em>BFS (in FS)</em>, <em>DFS (in FS)\n",
    "        - Not Standard\n",
    "            - <em>QLSTM</em>, <em>QNN</em>, <em>QLearning</em> \n",
    "    - <strong>heuristics</strong> This folder contains all the heuristics that we implemented for the A* algorithm and also for Greedy <br>\n",
    "        <em>Heuristic.py</em> Is the superclass of all heuristics \n",
    "        - <em>Manhattan</em>, <em>Euclidean</em>, <em>SManhattan (later we'll explain this one)</em>, <em>Chebysev</em>\n",
    "    - <strong>pseudo_heuristics</strong> This folder contains all the so called by us pseudo heuristics that we implemented for the A* algorithm and also for Greedy, this part of our real contribution to the \"field\"\n",
    "        <em>PseudoHeuristic.py</em> Is the superclass of all pseudo heuristics\n",
    "        - <em> CNN & LSTM <em> are pseudo heuristic that uses a CNN or an LSTM to predict the next action, <br> takes the whole map pixels as input and it has to return the distance from the goal (spoiler: both doesn't work well, but we din't won't to waste time on it)\n",
    "        - <em> NN <em> Same as CNN and LSTM but it takes the chars map, and still doesn't work well\n",
    "        - <em> NNHeuristic <em> <strong>THIS</strong> is the pseudo heuristic that uses a NN which we trained to approximate the Manhattan distance, <br> it takes only the starting and ending position as input and it returns the distance between them. <br> (It works really well, too much, outperforming in most cases all the other heuristics improving the performance of AStar by a lot)\n",
    "    - <strong>QLearning</strong> This folder contains all the Reinforcement Learning basics that we implemented\n",
    "    - <em>AnimateGif.py</em> This class is used to create the gif of the maze solving process\n",
    "    - <em>HeuristicUtils.py & utils.py</em> Just utils used by many of our algorithms\n",
    "- <font><strong>data</strong></font> The folder that contains all the data, with a dedicated dataset class for reading the files, that we used for our experiments with NNs approaches (generated by us)\n",
    "- <font><strong>Papers</strong></font> The folder that contains some papers that we used as inspiration for our work\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba27f105c027730b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Our Goal\n",
    "#### Our aim is nothing short of finding something interesting in the field of Efficiently Solving Mazes in Minihack."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "748fe438b4f83392"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project\n",
    "Let's dive into the details of our masterpiece. Brace yourself; it's going to be an interesting journey.\n",
    "###### Now that you're all set, let's dive into the good stuff. We'll start with a brief standard algorithm comparison, then we'll move on to the more interesting stuff."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d51c12af64ebb0d2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 188.40it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 178.98it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 185.48it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 186.46it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 188.55it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 190.19it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 185.87it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 193.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:| \n| A* <br> Manhattan  | 0.166 | 49 | 27 | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | 0.114  | 51 | 27 | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n| BFS              | 0.116 | 65 | 27 | ![BFS](TestsAnimations/BFS.gif) | Dijkstra         | 0.103 | 65 | 27 | ![Dijkstra](TestsAnimations/Dijkstra.gif) |\n| DFS              | 0.108 | 96 | 27 | ![DFS](TestsAnimations/DFS.gif) | Greedy <br> Manhattan | 0.11 | 39 | 28 | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | \n| Greedy <br> Euclidean | 0.112 | 38 | 28 | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) | A* <br> Chebysev | 0.109 | 52 | 27 | ![AStarChebysev](TestsAnimations/AStarChebysev.gif) |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the standard libraries we created\n",
    "from nextdataAI import AStar, DFS, BFS, Dijkstra, Greedy\n",
    "# Generate a random seed\n",
    "import random\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "results = {}\n",
    "\n",
    "# seed = random.randint(0, 1000000)\n",
    "# To be sure that we are all working on the same maze we'll use this seed, so you can reproduce our results\n",
    "seed = 208269\n",
    "# Set the environment name (A 9x9 maze)\n",
    "env_name = 'MiniHack-MazeWalk-Mapped-15x15-v0'\n",
    "\n",
    "# h function can be 'Manhattan', 'Euclidean' it will be taken by our utils automatically\n",
    "# Create the algorithms\n",
    "astar_manhattan = AStar(env_name=env_name, h='manhattan', name='AStarManhattan', animate=True)\n",
    "astar_euclidean = AStar(env_name=env_name, h='euclidean', name='AStarEuclidean', animate=True)\n",
    "astar_chebysev = AStar(env_name=env_name, h='chebysev', name='AStarChebysev', animate=True)\n",
    "dfs = DFS(env_name=env_name, name='DFS', animate=True)\n",
    "bfs = BFS(env_name=env_name, name='BFS', animate=True)\n",
    "dijkstra = Dijkstra(env_name=env_name, name='Dijkstra', animate=True)\n",
    "greedy_manhattan = Greedy(env_name=env_name, h='manhattan', name='GreedyManhattan', animate=True)\n",
    "greedy_euclidean = Greedy(env_name=env_name, h='euclidean', name='GreedyEuclidean', animate=True)\n",
    "\n",
    "# Execute the algorithms\n",
    "results['AStarManhattan'] = astar_manhattan(seed=seed)\n",
    "results['AStarEuclidean'] = astar_euclidean(seed=seed)\n",
    "results['AStarChebysev'] = astar_chebysev(seed=seed)\n",
    "results['DFS'] = dfs(seed=seed)\n",
    "results['BFS'] = bfs(seed=seed)\n",
    "results['Dijkstra'] = dijkstra(seed=seed)\n",
    "results['GreedyManhattan'] = greedy_manhattan(seed=seed)\n",
    "results['GreedyEuclidean'] = greedy_euclidean(seed=seed)\n",
    "\n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:| \n",
    "| A* <br> Manhattan  | {took['AStarManhattan']} | {len(results['AStarManhattan'][-2])} | {len(results['AStarManhattan'][-3])} | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | {took['AStarEuclidean']}  | {len(results['AStarEuclidean'][-2])} | {len(results['AStarEuclidean'][-3])} | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n",
    "| BFS              | {took['BFS']} | {len(results['BFS'][-2])} | {len(results['BFS'][-3])} | ![BFS](TestsAnimations/BFS.gif) | Dijkstra         | {took['Dijkstra']} | {len(results['Dijkstra'][-2])} | {len(results['Dijkstra'][-3])} | ![Dijkstra](TestsAnimations/Dijkstra.gif) |\n",
    "| DFS              | {took['DFS']} | {len(results['DFS'][-2])} | {len(results['DFS'][-3])} | ![DFS](TestsAnimations/DFS.gif) | Greedy <br> Manhattan | {took['GreedyManhattan']} | {len(results['GreedyManhattan'][-2])} | {len(results['GreedyManhattan'][-3])} | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | \n",
    "| Greedy <br> Euclidean | {took['GreedyEuclidean']} | {len(results['GreedyEuclidean'][-2])} | {len(results['GreedyEuclidean'][-3])} | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) | A* <br> Chebysev | {took['AStarChebysev']} | {len(results['AStarChebysev'][-2])} | {len(results['AStarChebysev'][-3])} | ![AStarChebysev](TestsAnimations/AStarChebysev.gif) |\n",
    "'''\n",
    "\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:31:23.335312Z",
     "start_time": "2024-01-24T23:31:13.438352Z"
    }
   },
   "id": "52fe2da11b71d240",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de76d007703b78fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Nice, we can clearly see in <font color=\"b6b529\"><strong>Yellow</strong></font> the visited cells, in <font color=\"1b54c7\"><strong>Blue</strong></font> the path found by the algorithm. <br> <strong>Also in the table we can clearly see the time taken by the algorithm, the number of visited cells and the path it found. </strong><br> We can clearly see that in small mazes, the Greedy algorithm is the best one, but we'll later how A* will be really improved by our contribution. <br>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f5e92bfc06abef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Genetic Algorithms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8d44ac4b088985a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation: 2 | Best Fitness: 0: 100%|██████████| 100/100 [06:05<00:00,  3.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | \n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|\n| Genetic          | 371.261 | 1001 | 1001 | ![Genetic](TestsAnimations/Genetic.gif) |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nextdataAI import Genetic\n",
    "\n",
    "# With bigger mazes, the process is too long, so we'll use a smaller one\n",
    "small_env_name = 'MiniHack-MazeWalk-Mapped-9x9-v0'\n",
    "# Create the algorithm\n",
    "genetic = Genetic(env_name=small_env_name, name='Genetic', animate=True)\n",
    "\n",
    "# Execute the algorithm\n",
    "results['Genetic'] = genetic(seed=seed)\n",
    "\n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | \n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| Genetic          | {took['Genetic']} | {len(results['Genetic'][-2])} | {len(results['Genetic'][-3])} | ![Genetic](TestsAnimations/Genetic.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:37:34.643720Z",
     "start_time": "2024-01-24T23:31:23.329359Z"
    }
   },
   "id": "2ea249141e705b34",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The brains are not braining today, but we know someone else have done it better than us, so we'll skip it. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6c8376f746b034"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's start with QLearning\n",
    "### QTable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f940722840c5d94c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [00:00<00:03, 272.12steps/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 338.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | \n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|\n| QTable          | 1.248 | 167 | 167 | ![QTable](TestsAnimations/QTable.gif) |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nextdataAI import QTable\n",
    "\n",
    "# Create the algorithm\n",
    "qlearning = QTable(env_name=small_env_name, animate=True)\n",
    "\n",
    "# Execute the algorithm\n",
    "results['QTable'] = qlearning(seed=seed)\n",
    "\n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | \n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| QTable          | {took['QTable']} | {len(results['QTable'][-2])} | {len(results['QTable'][-3])} | ![QTable](TestsAnimations/QTable.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:37:35.946700Z",
     "start_time": "2024-01-24T23:37:34.638839Z"
    }
   },
   "id": "e22b7789733a522f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The question is, does it work?\n",
    "#### No it doesn't, but it was a nice try which we retained not to be explored in a deeper way for the purpose of this project."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee360a11ae683d05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QNN and QLSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8de5a8baaa433e51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from nextdataAI import QNN, QLSTM\n",
    "# \n",
    "# # Create the algorithm\n",
    "# qnn = QNN(env_name=small_env_name, animate=True)\n",
    "# qlstm = QLSTM(env_name=small_env_name, animate=True)\n",
    "# \n",
    "# # Execute the algorithm\n",
    "# results['QNN'] = qnn(seed=seed)\n",
    "# results['QLSTM'] = qlstm(seed=seed)\n",
    "# \n",
    "# took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "# text = f'''\n",
    "# | Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "# |:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "# | QNN              | {took['QNN']} | {len(results['QNN'][-2])} | {len(results['QNN'][-3])} | ![QNN](TestsAnimations/QNN.gif) | QLSTM            | {took['QLSTM']} | {len(results['QLSTM'][-2])} | {len(results['QLSTM'][-3])} | ![QLSTM](TestsAnimations/QLSTM.gif) |\n",
    "# '''\n",
    "# display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:37:35.947297Z",
     "start_time": "2024-01-24T23:37:35.943327Z"
    }
   },
   "id": "9dde4317014fd534",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### We had a big trouble to run these algorithms on the notebook. But the results were discrete <br> so we decided to keep them even if they are not that good. We are not gonna show the final comparison for these."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfeb930bc7bb5dd9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Really Nice, it was a nice try... but we wanted to do a step further, <br> so we decided to create a Neural Network that approximates the Manhattan distance between a starting point a the target point. <br> No other information is given to the NN, just the starting point and the target point. <br> We don't want it to learn something about the maze, we just want it to learn the distance between the two points. <br> We trained it with a training dataset of ~33000 mazes, a dataset made by us.\n",
    "\n",
    "## Here comes the strange part\n",
    "\n",
    "###### We are not gonna show the CNN, LSTM, NN, that try to find the real path between the starting point and the target point. <br> This is to be more brief about the report, but you can find them in the <strong>pseudo_heuristics</strong> folder, <br> and you can run them by yourself with some specifications, they are not that interesting, but they are there. <br> It took some time to train them, but it was a pretty \"not involving\" task, so we did it. <br> <br>\n",
    "\n",
    "## We present you the NNHeuristic, our pseudo heuristic approach for solving mazes with A*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f0d24936717393"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 188.79it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 193.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n| A* NNHeuristic| 1.393 | 37 | 27 | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy NNHeuristic | 2.432 | 39 | 28 | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "astar_nnheuristic = AStar(env_name=env_name, h='nnmanhattan', name='AStarNNHeuristic', animate=True)\n",
    "greedy_nnheuristic = Greedy(env_name=env_name, h='nnmanhattan', name='GreedyNNHeuristic', animate=True)\n",
    "\n",
    "# Execute the algorithm\n",
    "results['AStarNNHeuristic'] = astar_nnheuristic(seed=seed)\n",
    "results['GreedyNNHeuristic'] = greedy_nnheuristic(seed=seed)\n",
    "\n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* NNHeuristic| {took['AStarNNHeuristic']} | {len(results['AStarNNHeuristic'][-2])} | {len(results['AStarNNHeuristic'][-3])} | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy NNHeuristic | {took['GreedyNNHeuristic']} | {len(results['GreedyNNHeuristic'][-2])} | {len(results['GreedyNNHeuristic'][-3])} | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:37:40.922230Z",
     "start_time": "2024-01-24T23:37:35.947252Z"
    }
   },
   "id": "ef9b86789bc557bb",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To have a brief comparison between the heuristics and our \"pseudo heuristic\" we'll show the table with the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95c6046d79547f6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n| A* <br> NNHeuristic| 1.393 | 37 | 27 | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy <br> NNHeuristic | 2.432 | 39 | 28 | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n| A* <br> Manhattan  | 0.166 | 49 | 27 | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | 0.114  | 51 | 27 | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n| Greedy <br> Manhattan | 0.11 | 39 | 28 | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | Greedy <br> Euclidean | 0.112 | 38 | 28 | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> NNHeuristic| {took['AStarNNHeuristic']} | {len(results['AStarNNHeuristic'][-2])} | {len(results['AStarNNHeuristic'][-3])} | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy <br> NNHeuristic | {took['GreedyNNHeuristic']} | {len(results['GreedyNNHeuristic'][-2])} | {len(results['GreedyNNHeuristic'][-3])} | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n",
    "| A* <br> Manhattan  | {took['AStarManhattan']} | {len(results['AStarManhattan'][-2])} | {len(results['AStarManhattan'][-3])} | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | {took['AStarEuclidean']}  | {len(results['AStarEuclidean'][-2])} | {len(results['AStarEuclidean'][-3])} | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n",
    "| Greedy <br> Manhattan | {took['GreedyManhattan']} | {len(results['GreedyManhattan'][-2])} | {len(results['GreedyManhattan'][-3])} | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | Greedy <br> Euclidean | {took['GreedyEuclidean']} | {len(results['GreedyEuclidean'][-2])} | {len(results['GreedyEuclidean'][-3])} | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:37:40.922954Z",
     "start_time": "2024-01-24T23:37:40.919260Z"
    }
   },
   "id": "df8f3c7c34fbf781",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## As we can clearly see from the table above, our pseudo heuristic outperforms all the other heuristics, <br> and it's really pushing to the real path, so we can say that it's a really good approximation of the real distance. <br> <br>\n",
    "### Let's see how it performs on bigger mazes \n",
    "##### For the bigger mazes we'll use the a new seed, so we can compare the results with the previous ones."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9babc01d6f082ea"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:01<00:00, 92.22it/s]\n",
      "100%|██████████| 106/106 [00:01<00:00, 89.64it/s]\n",
      "100%|██████████| 106/106 [00:01<00:00, 86.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n| A* <br> NNHeuristic| 5.644 | 200 | 107 | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) | A* <br> Manhattan  | 0.103 | 287 | 107 | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n| A* <br> Euclidean  | 0.106  | 288 | 107 | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | \n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "# Big maze\n",
    "large_env_name = 'MiniHack-MazeWalk-Mapped-45x19-v0'\n",
    "# As before, we'll use a seed to be sure that we are all working on the same maze, and the experiments are reproducible\n",
    "# large_seed = random.randint(0, sys.maxsize)\n",
    "large_seed = 5220663474396757845\n",
    "# Create the algorithm\n",
    "astar_nnheuristic_large = AStar(env_name=large_env_name, h='nnmanhattan', name='AStarNNHeuristicLarge', animate=True)\n",
    "astar_manhattan_large = AStar(env_name=large_env_name, h='manhattan', name='AStarManhattanLarge', animate=True)\n",
    "astar_euclidean_large = AStar(env_name=large_env_name, h='euclidean', name='AStarEuclideanLarge', animate=True)\n",
    "\n",
    "# Execute the algorithm\n",
    "results['AStarNNHeuristicLarge'] = astar_nnheuristic_large(seed=large_seed)\n",
    "results['AStarManhattanLarge'] = astar_manhattan_large(seed=large_seed)\n",
    "results['AStarEuclideanLarge'] = astar_euclidean_large(seed=large_seed)\n",
    "\n",
    "# Round the time to 3 decimals\n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> NNHeuristic| {took['AStarNNHeuristicLarge']} | {len(results['AStarNNHeuristicLarge'][-2])} | {len(results['AStarNNHeuristicLarge'][-3])} | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) | A* <br> Manhattan  | {took['AStarManhattanLarge']} | {len(results['AStarManhattanLarge'][-2])} | {len(results['AStarManhattanLarge'][-3])} | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
    "| A* <br> Euclidean  | {took['AStarEuclideanLarge']}  | {len(results['AStarEuclideanLarge'][-2])} | {len(results['AStarEuclideanLarge'][-3])} | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | \n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:38:09.226669Z",
     "start_time": "2024-01-24T23:37:40.924265Z"
    }
   },
   "id": "f0c54f87cc35c81a",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What a pleasure to see our pseudo heuristic working so well\n",
    "### But Why ? \n",
    "##### After some research and comparison of the manhattan distance and the euclidean distance, we found that the distance that our pseudo heuristic approximates is the... <br> We don't know actually, at the best of our knowledge there was no similar approaches in the literature... And we found out it is trying to aproximate the <strong>SManhattan distance</strong> (S for strange). <br> <br>\n",
    "### What is the SManhattan distance?\n",
    "##### The SManhattan distance is the Manhattan distance with a little twist, it's the Manhattan distance mutlipied by a factor that is a costant.."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a0fb168997792f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We took our version of the Manhattan distance and we modified it to be the SManhattan distance... being defined as:\n",
    "#### h(start, end) = (abs(start.x - end.x) + abs(start.y - end.y)) * 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10d3e48ab620dec3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:01<00:00, 90.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": "\n| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n| A* <br> SManhattan| 0.107 | 201 | 107 | ![AStarSManhattanLarge](TestsAnimations/AStarSManhattanLarge.gif) | A* <br> Manhattan  | 0.103 | 287 | 107 | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n| A* <br> Euclidean  | 0.106  | 288 | 107 | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | A* <br> NNHeuristic| 5.644 | 200 | 107 | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "# Big maze\n",
    "large_env_name = 'MiniHack-MazeWalk-Mapped-45x19-v0'\n",
    "\n",
    "# Create the algorithm\n",
    "astar_smanhattan_large = AStar(env_name=large_env_name, h='smanhattan', name='AStarSManhattanLarge', animate=True)\n",
    "\n",
    "# Execute the algorithm\n",
    "results['AStarSManhattanLarge'] = astar_smanhattan_large(seed=large_seed)\n",
    "\n",
    "# Round the time to 3 decimals\n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> SManhattan| {took['AStarSManhattanLarge']} | {len(results['AStarSManhattanLarge'][-2])} | {len(results['AStarSManhattanLarge'][-3])} | ![AStarSManhattanLarge](TestsAnimations/AStarSManhattanLarge.gif) | A* <br> Manhattan  | {took['AStarManhattanLarge']} | {len(results['AStarManhattanLarge'][-2])} | {len(results['AStarManhattanLarge'][-3])} | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
    "| A* <br> Euclidean  | {took['AStarEuclideanLarge']}  | {len(results['AStarEuclideanLarge'][-2])} | {len(results['AStarEuclideanLarge'][-3])} | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | A* <br> NNHeuristic| {took['AStarNNHeuristicLarge']} | {len(results['AStarNNHeuristicLarge'][-2])} | {len(results['AStarNNHeuristicLarge'][-3])} | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:38:15.703331Z",
     "start_time": "2024-01-24T23:38:09.222793Z"
    }
   },
   "id": "1e6f8f1bb5262524",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### As we can see, the SManhattan distance is the best heuristic for A* in this case, <br> but we can't say that it's the best heuristic for all the mazes. <br> Also we can't say that it's the best heuristic for Greedy, because it's not, by our tests it's equivalent to the Manhattan distance. <br> "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6ad38f76a4ade5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objective\n",
    "####  We created basically our heuristic for maze solving, and we wanted to see how it performs. It was a really interesting journey, and we are really proud of our work. <br> We also created a dataset of mazes, and this project itself which is a library, so we can use it in the future for other projects, or <strong>someone else can use it</strong> to create something even better. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "821e50e230a9f738"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset\n",
    "##### We provide with this project a dataset of mazes, that we created with a script that we wrote. We have both images and chars mazes, and we also have the solution for each maze. <br> We created the dataset to train our models. <br> <br> The dataset will not be provided with the project, but you can download it by yourself, it's a really small dataset, so it's not a problem. Read the README <br> <br>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9fd2ac2c54e7ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methodologies\n",
    "#### Now.. How can we compare our algorithms in terms of visited cells and path length? <br> <br> We can run each algorithm (that is worth trying) on many mazes and then comparing the mean of the time it took, the visited cells and the path length. <br> <br>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df00b26c925b8a49"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with the results\n",
    "df_final = pd.DataFrame(columns=['Algorithm', 'Solved', 'Path', 'Visited', 'Time', 'Maze_Name', 'Seed', 'Path_Length', 'Visited_Length'], dtype='object')\n",
    "\n",
    "env_name1 = 'MiniHack-MazeWalk-Mapped-45x19-v0'\n",
    "env_name2 = \"MiniHack-MazeWalk-Mapped-15x15-v0\"\n",
    "env_name3 = \"MiniHack-MazeWalk-Mapped-9x9-v0\"\n",
    "\n",
    "num_of_tries = 100\n",
    "\n",
    "from nextdataAI.pseudo_heuristics.NNManhattan import NNManhattan\n",
    "NNManhattan = NNManhattan()\n",
    "\n",
    "# Create a list of algorithms\n",
    "algorithms = [\n",
    "    AStar(env_name1, h='manhattan', name='ASTAR-Manhattan-Env1'),\n",
    "    AStar(env_name2, h='manhattan', name='ASTAR-Manhattan-Env2'),\n",
    "    AStar(env_name3, h='manhattan', name='ASTAR-Manhattan-Env3'),\n",
    "\n",
    "    AStar(env_name1, h='chebysev', name='ASTAR-Chebysev-Env1'),\n",
    "    AStar(env_name2, h='chebysev', name='ASTAR-Chebysev-Env2'),\n",
    "    AStar(env_name3, h='chebysev', name='ASTAR-Chebysev-Env3'),\n",
    "\n",
    "    AStar(env_name1, h='euclidean', name='ASTAR-EUCLIDEAN-Env1'),\n",
    "    AStar(env_name2, h='euclidean', name='ASTAR-EUCLIDEAN-Env2'),\n",
    "    AStar(env_name3, h='euclidean', name='ASTAR-EUCLIDEAN-Env3'),\n",
    "\n",
    "    AStar(env_name1, h='smanhattan', name='ASTAR-SManhattan-Env1'),\n",
    "    AStar(env_name2, h='smanhattan', name='ASTAR-SManhattan-Env2'),\n",
    "    AStar(env_name3, h='smanhattan', name='ASTAR-SManhattan-Env3'),\n",
    "\n",
    "    BFS(env_name1, name='BFS-Env1'),\n",
    "    BFS(env_name2, name='BFS-Env2'),\n",
    "    BFS(env_name3, name='BFS-Env3'),\n",
    "\n",
    "    DFS(env_name1, name='DFS-Env1'),\n",
    "    DFS(env_name2, name='DFS-Env2'),\n",
    "    DFS(env_name3, name='DFS-Env3'),\n",
    "\n",
    "    Greedy(env_name1, h='manhattan', name='GREEDY-Manhattan-Env1'),\n",
    "    Greedy(env_name2, h='manhattan', name='GREEDY-Manhattan-Env2'),\n",
    "    Greedy(env_name3, h='manhattan', name='GREEDY-Manhattan-Env3'),\n",
    "\n",
    "    Greedy(env_name1, h='smanhattan', name='GREEDY-SManhattan-Env1'),\n",
    "    Greedy(env_name2, h='smanhattan', name='GREEDY-SManhattan-Env2'),\n",
    "    Greedy(env_name3, h='smanhattan', name='GREEDY-SManhattan-Env3'),\n",
    "\n",
    "    Dijkstra(env_name1, name='DIJKSTRA-Env1'),\n",
    "    Dijkstra(env_name2, name='DIJKSTRA-Env2'),\n",
    "    Dijkstra(env_name3, name='DIJKSTRA-Env3'),\n",
    "\n",
    "    AStar(env_name1, h=NNManhattan, name='ASTAR-NNManhattan-Env1'),\n",
    "    AStar(env_name2, h=NNManhattan, name='ASTAR-NNManhattan-Env2'),\n",
    "    AStar(env_name3, h=NNManhattan, name='ASTAR-NNManhattan-Env3'),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:38:17.979351Z",
     "start_time": "2024-01-24T23:38:15.705527Z"
    }
   },
   "id": "34d8c87f87e89b99",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "# Define a function to run the algorithms\n",
    "def call(algorithm: Callable, seed_: int, i: int, name: str, local_env_name: str, pbar_: tqdm):\n",
    "    output = tuple([name]) + algorithm(seed_) + tuple([f'{local_env_name}_{i}']) + tuple([seed_])\n",
    "    pbar_.update(1)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:38:17.997442Z",
     "start_time": "2024-01-24T23:38:17.984631Z"
    }
   },
   "id": "e5a78f94f19bdfce",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Run the algorithms\n",
    "if not os.path.exists('results_all.csv'):\n",
    "    with tqdm(total=num_of_tries * len(algorithms)) as pbar:\n",
    "        for i in range(num_of_tries):\n",
    "            rand_seed = np.random.randint(0, sys.maxsize)\n",
    "            # insert into df\n",
    "            df = pd.DataFrame(\n",
    "                [call(algorithm=alg, seed_=rand_seed, i=i, name=alg.name, local_env_name=alg.env_name, pbar_=pbar) for alg in\n",
    "                 algorithms],\n",
    "                columns=['Algorithm', 'Solved', 'Path', 'Visited', 'Time', 'Maze_Name', 'Seed'])\n",
    "            # Save for each maze the len of the path and the visited cells\n",
    "            df['Path_Length'] = df['Path'].apply(lambda x: len(x))\n",
    "            df['Visited_Length'] = df['Visited'].apply(lambda x: len(x))\n",
    "            df = df.reset_index(drop=True)\n",
    "    \n",
    "            if df_final.empty:\n",
    "                df_final = df\n",
    "            else:\n",
    "                df_final = pd.concat([df_final, df])\n",
    "    df_final.to_csv('results_all.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:38:17.997934Z",
     "start_time": "2024-01-24T23:38:17.991867Z"
    }
   },
   "id": "c10d87d4dfd81193",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### We now have a csv file with all the results, we can now analyze them, but we are gonna do something better. Let's create a scoring system to compare the algorithms. <br> <br>\n",
    "### Scoring System (Assessment)\n",
    "##### Basically the ratio between the path length and the visited cells length. <br> <br>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bfd9b416d340207"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [(15, 41), (15, 42), (15, 43), (15, 44), (14, ...\n",
      "1    [(11, 36), (11, 35), (11, 34), (10, 34), (9, 3...\n",
      "2    [(7, 41), (7, 40), (7, 39), (7, 38), (8, 38), ...\n",
      "3    [(15, 41), (15, 42), (15, 43), (15, 44), (14, ...\n",
      "4    [(11, 36), (11, 35), (11, 34), (10, 34), (9, 3...\n",
      "Name: Path, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Algorithm       3000 non-null   object \n",
      " 1   Solved          3000 non-null   bool   \n",
      " 2   Path            3000 non-null   object \n",
      " 3   Visited         3000 non-null   object \n",
      " 4   Time            3000 non-null   float64\n",
      " 5   Maze_Name       3000 non-null   object \n",
      " 6   Seed            3000 non-null   int64  \n",
      " 7   Path_Length     3000 non-null   int64  \n",
      " 8   Visited_Length  3000 non-null   int64  \n",
      "dtypes: bool(1), float64(1), int64(3), object(4)\n",
      "memory usage: 190.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create a scoring system\n",
    "df_final = pd.read_csv('results_all.csv', index_col=0)\n",
    "df_final.reset_index(drop=True, inplace=True)   \n",
    "# Convert the string to list of tuples \n",
    "# Remove [ and ] at the beginning and the end\n",
    "df_final['Path'] = df_final['Path'].apply(lambda x: x[1:-1])\n",
    "df_final['Path'] = df_final['Path'].apply(lambda x: list(eval(x)))\n",
    "print(df_final['Path'].head())\n",
    "print(df_final.info())\n",
    "\n",
    "df_final['Solution_Score'] = df_final['Path'].apply(lambda x: sum(abs(int(x[coord][0]) - int(x[coord + 1][0])) + abs(int(x[coord][1]) - int(x[coord + 1][1])) for coord in range(len(x) - 1)))\n",
    "df_final['Solution_Score'] = 1 - df_final['Solution_Score']/ max(df_final['Solution_Score'])\n",
    "df_final['Solution_Score'] = df_final['Solution_Score'].apply(lambda x: round(x, 3))\n",
    "df_final['Path_Score'] = df_final['Path_Length']/df_final['Visited_Length']\n",
    "\n",
    "df_final = df_final[['Algorithm', 'Time', 'Visited_Length', 'Path_Length', 'Path_Score', 'Solution_Score']]\n",
    "df_final = df_final.groupby('Algorithm').agg({'Time': ['mean', 'std'], 'Visited_Length': ['mean', 'std'], 'Path_Length': ['mean', 'std'], 'Path_Score': ['mean', 'std'], 'Solution_Score': ['mean', 'std']})\n",
    "df_final.columns = ['_'.join(col) for col in df_final.columns.values]\n",
    "df_final = df_final.reset_index()\n",
    "df_final.sort_values(by=['Solution_Score_mean'], ascending=False, inplace=True)\n",
    "df_final.to_csv('results.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:43:03.042497Z",
     "start_time": "2024-01-24T23:43:02.610895Z"
    }
   },
   "id": "e60e9f1eccb828c9",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "Drumroll, please! The moment of truth has arrived."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f41a3e8d18afae5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results_maze_large = df_final[df_final['Algorithm'].str.contains('Env1')].sort_values(by=['Path_Score_mean'], ascending=False)\n",
    "results_maze_medium = df_final[df_final['Algorithm'].str.contains('Env2')].sort_values(by=['Path_Score_mean'], ascending=False)\n",
    "results_maze_small = df_final[df_final['Algorithm'].str.contains('Env3')].sort_values(by=['Path_Score_mean'], ascending=False)\n",
    "results_maze_large.reset_index(drop=True, inplace=True)\n",
    "results_maze_medium.reset_index(drop=True, inplace=True)\n",
    "results_maze_small.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:43:08.133907Z",
     "start_time": "2024-01-24T23:43:08.127764Z"
    }
   },
   "id": "1364e86aa92a742d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                Algorithm  Time_mean  Time_std  Visited_Length_mean  \\\n0   GREEDY-Manhattan-Env1   0.011785  0.007558               122.03   \n1  GREEDY-SManhattan-Env1   0.012042  0.007545               122.03   \n2  ASTAR-NNManhattan-Env1   3.822897  2.794039               129.22   \n3   ASTAR-SManhattan-Env1   0.012503  0.007660               131.24   \n4    ASTAR-Manhattan-Env1   0.013183  0.010007               160.89   \n\n   Visited_Length_std  Path_Length_mean  Path_Length_std  Path_Score_mean  \\\n0           84.575763             77.94        50.930497         0.686225   \n1           84.575763             77.94        50.930497         0.686225   \n2           96.026993             75.84        47.964153         0.678001   \n3           96.968194             75.84        47.964153         0.664671   \n4          109.755734             75.28        47.089230         0.541945   \n\n   Path_Score_std  Solution_Score_mean  Solution_Score_std  \n0        0.157906              0.69098            0.204586  \n1        0.157906              0.69098            0.204586  \n2        0.177119              0.69942            0.192659  \n3        0.172712              0.69942            0.192659  \n4        0.163292              0.70168            0.189126  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Time_mean</th>\n      <th>Time_std</th>\n      <th>Visited_Length_mean</th>\n      <th>Visited_Length_std</th>\n      <th>Path_Length_mean</th>\n      <th>Path_Length_std</th>\n      <th>Path_Score_mean</th>\n      <th>Path_Score_std</th>\n      <th>Solution_Score_mean</th>\n      <th>Solution_Score_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GREEDY-Manhattan-Env1</td>\n      <td>0.011785</td>\n      <td>0.007558</td>\n      <td>122.03</td>\n      <td>84.575763</td>\n      <td>77.94</td>\n      <td>50.930497</td>\n      <td>0.686225</td>\n      <td>0.157906</td>\n      <td>0.69098</td>\n      <td>0.204586</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GREEDY-SManhattan-Env1</td>\n      <td>0.012042</td>\n      <td>0.007545</td>\n      <td>122.03</td>\n      <td>84.575763</td>\n      <td>77.94</td>\n      <td>50.930497</td>\n      <td>0.686225</td>\n      <td>0.157906</td>\n      <td>0.69098</td>\n      <td>0.204586</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ASTAR-NNManhattan-Env1</td>\n      <td>3.822897</td>\n      <td>2.794039</td>\n      <td>129.22</td>\n      <td>96.026993</td>\n      <td>75.84</td>\n      <td>47.964153</td>\n      <td>0.678001</td>\n      <td>0.177119</td>\n      <td>0.69942</td>\n      <td>0.192659</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ASTAR-SManhattan-Env1</td>\n      <td>0.012503</td>\n      <td>0.007660</td>\n      <td>131.24</td>\n      <td>96.968194</td>\n      <td>75.84</td>\n      <td>47.964153</td>\n      <td>0.664671</td>\n      <td>0.172712</td>\n      <td>0.69942</td>\n      <td>0.192659</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ASTAR-Manhattan-Env1</td>\n      <td>0.013183</td>\n      <td>0.010007</td>\n      <td>160.89</td>\n      <td>109.755734</td>\n      <td>75.28</td>\n      <td>47.089230</td>\n      <td>0.541945</td>\n      <td>0.163292</td>\n      <td>0.70168</td>\n      <td>0.189126</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_maze_large.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:43:09.247175Z",
     "start_time": "2024-01-24T23:43:09.241756Z"
    }
   },
   "id": "10bcbe8c94b2ca99",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                Algorithm  Time_mean  Time_std  Visited_Length_mean  \\\n0  ASTAR-NNManhattan-Env2   1.047521  0.708385                34.13   \n1   ASTAR-SManhattan-Env2   0.011277  0.007620                34.55   \n2   GREEDY-Manhattan-Env2   0.011131  0.007682                35.11   \n3  GREEDY-SManhattan-Env2   0.011163  0.007603                35.11   \n4    ASTAR-Manhattan-Env2   0.011269  0.007829                37.48   \n\n   Visited_Length_std  Path_Length_mean  Path_Length_std  Path_Score_mean  \\\n0           24.992385             23.47        15.930693         0.772143   \n1           25.176298             23.47        15.930693         0.765570   \n2           24.036544             24.21        16.623152         0.725002   \n3           24.036544             24.21        16.623152         0.725002   \n4           25.528942             23.47        15.930693         0.699493   \n\n   Path_Score_std  Solution_Score_mean  Solution_Score_std  \n0        0.179603              0.90992            0.064036  \n1        0.180732              0.90992            0.064036  \n2        0.155965              0.90693            0.066837  \n3        0.155965              0.90693            0.066837  \n4        0.174474              0.90992            0.064036  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Time_mean</th>\n      <th>Time_std</th>\n      <th>Visited_Length_mean</th>\n      <th>Visited_Length_std</th>\n      <th>Path_Length_mean</th>\n      <th>Path_Length_std</th>\n      <th>Path_Score_mean</th>\n      <th>Path_Score_std</th>\n      <th>Solution_Score_mean</th>\n      <th>Solution_Score_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ASTAR-NNManhattan-Env2</td>\n      <td>1.047521</td>\n      <td>0.708385</td>\n      <td>34.13</td>\n      <td>24.992385</td>\n      <td>23.47</td>\n      <td>15.930693</td>\n      <td>0.772143</td>\n      <td>0.179603</td>\n      <td>0.90992</td>\n      <td>0.064036</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ASTAR-SManhattan-Env2</td>\n      <td>0.011277</td>\n      <td>0.007620</td>\n      <td>34.55</td>\n      <td>25.176298</td>\n      <td>23.47</td>\n      <td>15.930693</td>\n      <td>0.765570</td>\n      <td>0.180732</td>\n      <td>0.90992</td>\n      <td>0.064036</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GREEDY-Manhattan-Env2</td>\n      <td>0.011131</td>\n      <td>0.007682</td>\n      <td>35.11</td>\n      <td>24.036544</td>\n      <td>24.21</td>\n      <td>16.623152</td>\n      <td>0.725002</td>\n      <td>0.155965</td>\n      <td>0.90693</td>\n      <td>0.066837</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GREEDY-SManhattan-Env2</td>\n      <td>0.011163</td>\n      <td>0.007603</td>\n      <td>35.11</td>\n      <td>24.036544</td>\n      <td>24.21</td>\n      <td>16.623152</td>\n      <td>0.725002</td>\n      <td>0.155965</td>\n      <td>0.90693</td>\n      <td>0.066837</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ASTAR-Manhattan-Env2</td>\n      <td>0.011269</td>\n      <td>0.007829</td>\n      <td>37.48</td>\n      <td>25.528942</td>\n      <td>23.47</td>\n      <td>15.930693</td>\n      <td>0.699493</td>\n      <td>0.174474</td>\n      <td>0.90992</td>\n      <td>0.064036</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_maze_medium.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:43:11.637715Z",
     "start_time": "2024-01-24T23:43:11.631586Z"
    }
   },
   "id": "3125516dcd287b55",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                Algorithm  Time_mean  Time_std  Visited_Length_mean  \\\n0  ASTAR-NNManhattan-Env3   0.399369  0.223056                12.00   \n1   ASTAR-SManhattan-Env3   0.011111  0.007642                11.95   \n2    ASTAR-Manhattan-Env3   0.011035  0.007396                12.36   \n3    ASTAR-EUCLIDEAN-Env3   0.011041  0.007799                13.01   \n4     ASTAR-Chebysev-Env3   0.011254  0.008491                13.60   \n\n   Visited_Length_std  Path_Length_mean  Path_Length_std  Path_Score_mean  \\\n0            7.739444              9.63         5.176979         0.878512   \n1            7.576379              9.59         5.146530         0.875009   \n2            7.852838              9.49         5.042236         0.845445   \n3            8.129625              9.49         5.042236         0.811554   \n4            8.336363              9.49         5.042236         0.776940   \n\n   Path_Score_std  Solution_Score_mean  Solution_Score_std  \n0        0.162095              0.96548            0.020708  \n1        0.160810              0.96564            0.020586  \n2        0.158404              0.96604            0.020169  \n3        0.165666              0.96604            0.020169  \n4        0.169756              0.96604            0.020169  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Time_mean</th>\n      <th>Time_std</th>\n      <th>Visited_Length_mean</th>\n      <th>Visited_Length_std</th>\n      <th>Path_Length_mean</th>\n      <th>Path_Length_std</th>\n      <th>Path_Score_mean</th>\n      <th>Path_Score_std</th>\n      <th>Solution_Score_mean</th>\n      <th>Solution_Score_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ASTAR-NNManhattan-Env3</td>\n      <td>0.399369</td>\n      <td>0.223056</td>\n      <td>12.00</td>\n      <td>7.739444</td>\n      <td>9.63</td>\n      <td>5.176979</td>\n      <td>0.878512</td>\n      <td>0.162095</td>\n      <td>0.96548</td>\n      <td>0.020708</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ASTAR-SManhattan-Env3</td>\n      <td>0.011111</td>\n      <td>0.007642</td>\n      <td>11.95</td>\n      <td>7.576379</td>\n      <td>9.59</td>\n      <td>5.146530</td>\n      <td>0.875009</td>\n      <td>0.160810</td>\n      <td>0.96564</td>\n      <td>0.020586</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ASTAR-Manhattan-Env3</td>\n      <td>0.011035</td>\n      <td>0.007396</td>\n      <td>12.36</td>\n      <td>7.852838</td>\n      <td>9.49</td>\n      <td>5.042236</td>\n      <td>0.845445</td>\n      <td>0.158404</td>\n      <td>0.96604</td>\n      <td>0.020169</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ASTAR-EUCLIDEAN-Env3</td>\n      <td>0.011041</td>\n      <td>0.007799</td>\n      <td>13.01</td>\n      <td>8.129625</td>\n      <td>9.49</td>\n      <td>5.042236</td>\n      <td>0.811554</td>\n      <td>0.165666</td>\n      <td>0.96604</td>\n      <td>0.020169</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ASTAR-Chebysev-Env3</td>\n      <td>0.011254</td>\n      <td>0.008491</td>\n      <td>13.60</td>\n      <td>8.336363</td>\n      <td>9.49</td>\n      <td>5.042236</td>\n      <td>0.776940</td>\n      <td>0.169756</td>\n      <td>0.96604</td>\n      <td>0.020169</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_maze_small.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T23:43:13.765858Z",
     "start_time": "2024-01-24T23:43:13.760724Z"
    }
   },
   "id": "979e3b4942c23f87",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Small Considerations\n",
    "#### We can see, our Pseudo Heuristic is doing well... Always being in the top scores. <br> It certainly takes time since it's a NN, it will be better to use in batch <br> by giving it all the possible starting points and target points, and then use the output. <br> Also our SManhattan is really good, both are doing great. <br> <br> To be fair we have to say that there are some cases as we can see from the mean scores in which there is a negligible discrepancies, <br> but since our are Pseudo Heuristics we can't obviously guarantee the properties of an Heuristic. <br> <br>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c46ea5fc128ea16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Challenges Faced\n",
    "#### We had a lot of challenging moments on trying to use the minihack envirorment... <br> It is not well documented, and it's not easy to use. Also it doesn't provide the Animation that we provided... <br> We took our shot and we created it by ourselves, it was a really nice to see all the algorithms outcome. <br> <br> "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b66f5e13dfc4327"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "### In conclusion we are proud of this project, and the nice results that we got. <br> We have achieved better performance than the state of the art by just using some of our basic skills in the AI field. <br> The pseudo heuristic is interesting, and it took inspiration from some of the papers that we read <br> in which they used a so called Differential Heuristic. <br> Our contribution is to create a Neural Network that approximates the Manhattan distance, and then use it as a heuristic for A* and Greedy. <br> Also we further propose a new heuristic that we called SManhattan, which is the Manhattan distance multiplied by a constant. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73ebe8cb095dad5d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Future Work\n",
    "### Finally we want to propose the dataset we created as well as the library <br> itself as a starting point for future generations of AIF students that can extend our work and improve it. <br> <br> Our journey doesn't end here. Many tools such as Prolog or algorithms like Monte-Carlo can be applied to this field, <br> also many of the not informed practical algorithms can be implemented. <br> <br> We also wanted to try to implement a new algorithm that we called <strong>QStar</strong> which is a mix between QLearning and A*, but this is another story."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d66954f581ea9ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Acknowledgments (Related Works)\n",
    "The course matherials were really useful for this project, obviously.\n",
    "\n",
    "In the field of our project we found some interesting papers that we used as inspiration for our work:\n",
    "- [The Compressed Differential Heuristic](https://cdn.aaai.org/ojs/7823/7823-13-11351-1-2-20201228.pdf)\n",
    "- [Reinforcement Learning with A* and a Deep Heuristic](https://arxiv.org/abs/1811.07745)\n",
    "- [Structured World Representations in Maze-Solving Transformers](https://arxiv.org/abs/2312.02566)\n",
    "\n",
    "Also a project for probably University of Petr Posik\n",
    "- [Robot localization in a maze](https://cw.fel.cvut.cz/b182/_media/courses/ui/tasks/robot_in_maze_description.pdf)\n",
    "\n",
    "We'd like to aknowledge the following resources that contributed to our ideas for this project:\n",
    "- [Minihack Documentation](https://nethackwiki.com/wiki/Minihack)\n",
    "- [Minihack Github](https://github.com/facebookresearch/minihack)\n",
    "- [StackOverflow](https://stackoverflow.com/)\n",
    "- [Github Community](https://github.com/)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d01d0cfe991dfa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Appendix\n",
    "\n",
    "### We both contributed to the project in the same way. We split some parts of the project such as <br> Paul written some of basic algorithms and the QTable, <br> Stefano contributed to the part of implementing the QLearning agents, the QLSTM and the QNN. <br> We both contributed to this final notebook. <br> Then the utils where actually taken from the course Hands-On, and we modified them to fit our needs. <br> The Animator class was made from scratch, as well as almost all the code in our library and the dataset.\n",
    "\n",
    "##### The project is available on [Github](https://github.com/nextdataAI/aif.git) as well as all the metrics which are not truly representative since we worked many times from the University on the same pc.\n",
    "\n",
    "We loved trying to figure out how some of the arguments seen in the Search Chapter of the course could be applied to the Minihack environment. <br> We also loved trying to figure out how to create a library that integrates part of the algorithms seen, even if we wanted to add more of them. <br> Also we further proposed a new heuristic that we called SManhattan. <br> <br> We are really proud of our work, and we hope that it is actually enjoyable. <br> "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e5b2e9d4a9a3f6"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
