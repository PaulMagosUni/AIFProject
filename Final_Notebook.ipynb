{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9170c3bc",
   "metadata": {},
   "source": [
    "# Project Report - \"The Magoni Adventure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2793b28100c28",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Introduction\n",
    "#### Welcome to the most thrilling project report you'll read today! Our project, codenamed <strong>\"The Magoni Adventure\"</strong> is a masterpiece in the making. We hope you enjoy reading it as much as we enjoyed writing it. <br> We are <font color='fb9f89'><strong>Paul Magos</strong></font> & <font color='fb9f89'><strong>Stefano Zanoni</strong></font>, and we're here to take you on a journey of algorithms comparison (with some strange approaches). Our aim is nothing short of finding something interesting in the field of <font color='green'><strong>Efficiently Solving Mazes in Minihack</strong></font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c12af64ebb0d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Start\n",
    "#### Now that you're all set, let's dive into the good stuff. We'll start with a brief standard algorithm comparison, then we'll move on to the more interesting stuff. First we'll compare many of the algorithms seen in the course, implemented by us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9471e24bc30ed9a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.565455Z",
     "start_time": "2024-01-25T15:40:11.401338Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: AStarManhattan Time:0.2654862403869629 Visited:49 Path:27\n",
      "Algorithm: AStarEuclidean Time:0.14666199684143066 Visited:51 Path:27\n",
      "Algorithm: AStarChebysev Time:0.11014294624328613 Visited:52 Path:27\n",
      "Algorithm: DFS Time:0.10768485069274902 Visited:96 Path:27\n",
      "Algorithm: BFS Time:0.11055302619934082 Visited:65 Path:27\n",
      "Algorithm: Dijkstra Time:0.10345911979675293 Visited:65 Path:27\n",
      "Algorithm: GreedyManhattan Time:0.12991118431091309 Visited:39 Path:28\n",
      "Algorithm: GreedyEuclidean Time:0.11697793006896973 Visited:38 Path:28\n"
     ]
    }
   ],
   "source": [
    "# Import the standard libraries we created\n",
    "from nextdataAI import AStar, DFS, BFS, Dijkstra, Greedy\n",
    "import os\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# Generate a random seed\n",
    "import random\n",
    "import pickle\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "results = {} if not os.path.exists('results.pkl') else pickle.load(open('results.pkl', 'rb'))\n",
    "\n",
    "# seed = random.randint(0, 1000000)\n",
    "# To be sure that we are all working on the same maze we'll use this seed, so you can reproduce our results\n",
    "seed = 208269\n",
    "# Set the environment name (A 9x9 maze)\n",
    "env_name = 'MiniHack-MazeWalk-Mapped-15x15-v0'\n",
    "\n",
    "keys = ['AStarManhattan', 'AStarEuclidean', 'AStarChebysev', 'DFS', 'BFS', 'Dijkstra', 'GreedyManhattan', 'GreedyEuclidean']\n",
    "\n",
    "if any([kw not in results for kw in keys]):\n",
    "    # h function can be 'Manhattan', 'Euclidean' it will be taken by our utils automatically\n",
    "    # Create the algorithms\n",
    "    astar_manhattan = AStar(env_name=env_name, h='manhattan', name='AStarManhattan', animate=True)\n",
    "    astar_euclidean = AStar(env_name=env_name, h='euclidean', name='AStarEuclidean', animate=True)\n",
    "    astar_chebysev = AStar(env_name=env_name, h='chebysev', name='AStarChebysev', animate=True)\n",
    "    dfs = DFS(env_name=env_name, name='DFS', animate=True)\n",
    "    bfs = BFS(env_name=env_name, name='BFS', animate=True)\n",
    "    dijkstra = Dijkstra(env_name=env_name, name='Dijkstra', animate=True)\n",
    "    greedy_manhattan = Greedy(env_name=env_name, h='manhattan', name='GreedyManhattan', animate=True)\n",
    "    greedy_euclidean = Greedy(env_name=env_name, h='euclidean', name='GreedyEuclidean', animate=True)\n",
    "\n",
    "    # Execute the algorithms\n",
    "    results['AStarManhattan'] = astar_manhattan(seed=seed)\n",
    "    results['AStarEuclidean'] = astar_euclidean(seed=seed)\n",
    "    results['AStarChebysev'] = astar_chebysev(seed=seed)\n",
    "    results['DFS'] = dfs(seed=seed)\n",
    "    results['BFS'] = bfs(seed=seed)\n",
    "    results['Dijkstra'] = dijkstra(seed=seed)\n",
    "    results['GreedyManhattan'] = greedy_manhattan(seed=seed)\n",
    "    results['GreedyEuclidean'] = greedy_euclidean(seed=seed)\n",
    "\n",
    "\n",
    "print('\\nResults:')\n",
    "for kw in keys:\n",
    "    print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacfa72",
   "metadata": {},
   "source": [
    "The results are not overwhelming.\n",
    "We can see also the results of the comparison in the Appendix [[3]](#Comparison1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d44ac4b088985a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b9e89f63809bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.569323Z",
     "start_time": "2024-01-25T15:40:16.566885Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: Genetic Time:377.514986038208 Visited:1001 Path:1001\n"
     ]
    }
   ],
   "source": [
    "from nextdataAI import Genetic\n",
    "\n",
    "# With bigger mazes, the process is too long, so we'll use a smaller one\n",
    "small_env_name = 'MiniHack-MazeWalk-Mapped-9x9-v0'\n",
    "if 'Genetic' not in results.keys():\n",
    "    # Create the algorithm\n",
    "    genetic = Genetic(env_name=small_env_name, name='Genetic', animate=True)\n",
    "\n",
    "    # Execute the algorithm\n",
    "    results['Genetic'] = genetic(seed=seed)\n",
    "\n",
    "keys = ['Genetic']\n",
    "\n",
    "print('\\nResults:')\n",
    "for kw in keys:\n",
    "    print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c8376f746b034",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### The brains are not braining today, but we know someone else have done it better than us, so we'll skip it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f940722840c5d94c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## QLearning\n",
    "### QTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db6788390fb01d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.572338Z",
     "start_time": "2024-01-25T15:40:16.570226Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: QTable Time:0.6680302619934082 Visited:71 Path:71\n"
     ]
    }
   ],
   "source": [
    "from nextdataAI import QTable\n",
    "\n",
    "if 'QTable' not in results.keys():\n",
    "\n",
    "    # Create the algorithm\n",
    "    qtable = QTable(env_name=small_env_name, animate=True)\n",
    "\n",
    "    # Execute the algorithm\n",
    "    results['QTable'] = qtable(seed=seed)\n",
    "\n",
    "keys = ['QTable']\n",
    "\n",
    "print('\\nResults:')\n",
    "for kw in keys:\n",
    "    print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee360a11ae683d05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### The question is, does it work? No it doesn't work well, but it was a nice try which we retained not to be explored in a deeper way for the purpose of this project. See also the Appendix [[4]](#Comparison2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5a8baaa433e51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### QNN and QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dde4317014fd534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.584230Z",
     "start_time": "2024-01-25T15:40:16.573508Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: QNN Time:18.191520929336548 Visited:11 Path:11\n",
      "Algorithm: QLSTM Time:154.4595320224762 Visited:18 Path:18\n"
     ]
    }
   ],
   "source": [
    "from nextdataAI import QNN, QLSTM\n",
    "\n",
    "if 'QNN' not in results.keys() or 'QLSTM' not in results.keys():\n",
    "    # Create the algorithm\n",
    "    qnn = QNN(env_name=env_name, animate=True)\n",
    "    qlstm = QLSTM(env_name=env_name, animate=True)\n",
    "\n",
    "    # Execute the algorithm\n",
    "    results['QNN'] = qnn(seed=seed)\n",
    "    results['QLSTM'] = qlstm(seed=seed)\n",
    "    \n",
    "keys = ['QNN', 'QLSTM']\n",
    "\n",
    "try:\n",
    "    print('\\nResults:')\n",
    "    for kw in keys:\n",
    "        for el in results[kw]:\n",
    "            if el is None:\n",
    "                continue\n",
    "        print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723d822",
   "metadata": {},
   "source": [
    "#### For a better understanding of the results we suggest to read the Appendix [[5]](#Comparison3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0d24936717393",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Here comes the strange part\n",
    "##### We decided to create a Neural Network that approximates the Manhattan distance between a starting point a the target point. <br> No other information is given to the NN, just the starting point and the target point. <br> We don't want it to learn something about the maze, we just want it to learn the distance between the two points. <br> We trained it with a training dataset of ~33000 mazes, a dataset made by us. <br> We are not gonna show the CNN, LSTM, NN, that try to find the real path between the starting point and the target point. <br> This is to be more brief about the report, but you can find them in the <strong>pseudo_heuristics</strong> folder, <br> and you can run them by yourself with some specifications, they are not that interesting, but they are there. <br> It took some time to train them, but it was a pretty \"not involving\" task, so we did it.\n",
    "### We present you the NNHeuristic, our pseudo heuristic approach for solving mazes with A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9b86789bc557bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.964566Z",
     "start_time": "2024-01-25T15:40:16.576950Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n",
      "\n",
      "Results:\n",
      "Algorithm: AStarNNHeuristic Time:1.4738359451293945 Visited:37 Path:27\n",
      "Algorithm: GreedyNNHeuristic Time:2.8895130157470703 Visited:39 Path:28\n"
     ]
    }
   ],
   "source": [
    "astar_nnheuristic = AStar(env_name=env_name, h='nnmanhattan', name='AStarNNHeuristic', animate=True)\n",
    "greedy_nnheuristic = Greedy(env_name=env_name, h='nnmanhattan', name='GreedyNNHeuristic', animate=True)\n",
    "if 'AStarNNHeuristic' not in results.keys() or 'GreedyNNHeuristic' not in results.keys():\n",
    "\n",
    "    # Execute the algorithm\n",
    "    results['AStarNNHeuristic'] = astar_nnheuristic(seed=seed)\n",
    "    results['GreedyNNHeuristic'] = greedy_nnheuristic(seed=seed)\n",
    "\n",
    "keys = ['AStarNNHeuristic', 'GreedyNNHeuristic']\n",
    "\n",
    "print('\\nResults:')\n",
    "for kw in keys:\n",
    "    print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9babc01d6f082ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### As we can clearly see from the results above, our pseudo heuristic outperforms all the other heuristics in A*, <br> and it's really pushing to the real path, so we can say that it's a really good approximation of the real distance. <br> Let's see how it performs on bigger mazes \n",
    "#### For the bigger mazes we'll use the a new seed, so we can compare the results with the previous ones. <br> A brief comparison of these two seeds can be found in the Appendix [[6]](#Comparison4) and [[7]](#Comparison5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c54f87cc35c81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.965681Z",
     "start_time": "2024-01-25T15:40:16.959765Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: AStarNNHeuristicLarge Time:6.423929691314697 Visited:200 Path:107\n",
      "Algorithm: AStarManhattanLarge Time:0.11173200607299805 Visited:287 Path:107\n",
      "Algorithm: AStarEuclideanLarge Time:0.21919488906860352 Visited:288 Path:107\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Big maze\n",
    "large_env_name = 'MiniHack-MazeWalk-Mapped-45x19-v0'\n",
    "# As before, we'll use a seed to be sure that we are all working on the same maze, and the experiments are reproducible\n",
    "# large_seed = random.randint(0, sys.maxsize)\n",
    "large_seed = 5220663474396757845\n",
    "\n",
    "if 'AStarNNHeuristicLarge' not in results.keys() or 'AStarManhattanLarge' not in results.keys() or 'AStarEuclideanLarge' not in results.keys():\n",
    "    # Create the algorithm\n",
    "    astar_nnheuristic_large = AStar(env_name=large_env_name, h='nnmanhattan', name='AStarNNHeuristicLarge', animate=True)\n",
    "    astar_manhattan_large = AStar(env_name=large_env_name, h='manhattan', name='AStarManhattanLarge', animate=True)\n",
    "    astar_euclidean_large = AStar(env_name=large_env_name, h='euclidean', name='AStarEuclideanLarge', animate=True)\n",
    "\n",
    "    # Execute the algorithm\n",
    "    results['AStarNNHeuristicLarge'] = astar_nnheuristic_large(seed=large_seed)\n",
    "    results['AStarManhattanLarge'] = astar_manhattan_large(seed=large_seed)\n",
    "    results['AStarEuclideanLarge'] = astar_euclidean_large(seed=large_seed)\n",
    "\n",
    "keys = ['AStarNNHeuristicLarge', 'AStarManhattanLarge', 'AStarEuclideanLarge']\n",
    "\n",
    "print('\\nResults:')\n",
    "for kw in keys:\n",
    "    print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fb168997792f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### It's actually better, furtherly, after some research and comparison of the manhattan distance and the euclidean distance, we found that the distance that our pseudo heuristic approximates is not a really known distance. <br> To have a better undestanding of the capabilities of our pseudo heuristic take a look at the Appendix [[8]](#Comparison6). <br> At the best of our knowledge there was no similar approaches in the literature and we found out it is trying to aproximate the <strong>SManhattan distance</strong> (S for strange). <br> The SManhattan distance is the Manhattan distance with a little twist, it's the Manhattan distance mutlipied by a factor that is a costant, defined by us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3e48ab620dec3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### We took our shot and made the SManhattan distance, defined as follows:\n",
    "$$\n",
    "h(start, end) = abs(start.x - end.x) + abs(start.y - end.y) * 3\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6f8f1bb5262524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:16.967145Z",
     "start_time": "2024-01-25T15:40:16.963496Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: AStarSManhattanLarge Time:0.10812211036682129 Visited:201 Path:107\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
       "| A* <br> SManhattan| 0.108 | 201 | 107 | ![AStarSManhattanLarge](TestsAnimations/AStarSManhattanLarge.gif) | A* <br> Manhattan  | 0.112 | 287 | 107 | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
       "| A* <br> Euclidean  | 0.219  | 288 | 107 | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | A* <br> NNHeuristic| 6.424 | 200 | 107 | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "# Big maze\n",
    "\n",
    "if 'AStarSManhattanLarge' not in results.keys():\n",
    "    # Create the algorithm\n",
    "    astar_smanhattan_large = AStar(env_name=large_env_name, h='smanhattan', name='AStarSManhattanLarge', animate=True)\n",
    "\n",
    "    # Execute the algorithm\n",
    "    results['AStarSManhattanLarge'] = astar_smanhattan_large(seed=large_seed)\n",
    "\n",
    "keys = ['AStarSManhattanLarge']\n",
    "print('\\nResults:')\n",
    "for kw in keys:\n",
    "    print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')\n",
    "    \n",
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> SManhattan| {took['AStarSManhattanLarge']} | {len(results['AStarSManhattanLarge'][-2])} | {len(results['AStarSManhattanLarge'][-3])} | ![AStarSManhattanLarge](TestsAnimations/AStarSManhattanLarge.gif) | A* <br> Manhattan  | {took['AStarManhattanLarge']} | {len(results['AStarManhattanLarge'][-2])} | {len(results['AStarManhattanLarge'][-3])} | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
    "| A* <br> Euclidean  | {took['AStarEuclideanLarge']}  | {len(results['AStarEuclideanLarge'][-2])} | {len(results['AStarEuclideanLarge'][-3])} | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | A* <br> NNHeuristic| {took['AStarNNHeuristicLarge']} | {len(results['AStarNNHeuristicLarge'][-2])} | {len(results['AStarNNHeuristicLarge'][-3])} | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad38f76a4ade5b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### As we can see, the SManhattan distance is really close to the NN Pseudo Heuristic for A* in this case, <br> but we can't say that it's the best heuristic for all the mazes. <br> Also we can't say that it's the best heuristic for Greedy, because it's not, by our tests it's equivalent to the Manhattan distance. <br> We added for a better understanding of our approach all the tests in the Appendix [[10]](#Allres1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df00b26c925b8a49",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Methodologies\n",
    "#### We wanted to compare our algorithms in terms of visited cells and path length <br> We can run each algorithm (that is worth trying) on many mazes and then comparing the mean of the time it took, the visited cells and the path length. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d8c87f87e89b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.115100Z",
     "start_time": "2024-01-25T15:40:16.972373Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'SGD', because it has 11 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:NNHeuristic:This is a pseudo-heuristic. It is not a real heuristic.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pickle.dump(results, open('results.pkl', 'wb'))\n",
    "# Create a dataframe with the results\n",
    "df_final = pd.DataFrame(columns=['Algorithm', 'Solved', 'Path', 'Visited', 'Time', 'Maze_Name', 'Seed', 'Path_Length', 'Visited_Length'], dtype='object')\n",
    "\n",
    "env_name1 = 'MiniHack-MazeWalk-Mapped-45x19-v0'\n",
    "env_name2 = \"MiniHack-MazeWalk-Mapped-15x15-v0\"\n",
    "env_name3 = \"MiniHack-MazeWalk-Mapped-9x9-v0\"\n",
    "\n",
    "num_of_tries = 100\n",
    "\n",
    "from nextdataAI.pseudo_heuristics.NNManhattan import NNManhattan\n",
    "NNManhattan = NNManhattan()\n",
    "\n",
    "# Create a list of algorithms\n",
    "algorithms = [\n",
    "    AStar(env_name1, h='manhattan', name='ASTAR-Manhattan-Env1'),\n",
    "    AStar(env_name2, h='manhattan', name='ASTAR-Manhattan-Env2'),\n",
    "    AStar(env_name3, h='manhattan', name='ASTAR-Manhattan-Env3'),\n",
    "\n",
    "    AStar(env_name1, h='chebysev', name='ASTAR-Chebysev-Env1'),\n",
    "    AStar(env_name2, h='chebysev', name='ASTAR-Chebysev-Env2'),\n",
    "    AStar(env_name3, h='chebysev', name='ASTAR-Chebysev-Env3'),\n",
    "\n",
    "    AStar(env_name1, h='euclidean', name='ASTAR-EUCLIDEAN-Env1'),\n",
    "    AStar(env_name2, h='euclidean', name='ASTAR-EUCLIDEAN-Env2'),\n",
    "    AStar(env_name3, h='euclidean', name='ASTAR-EUCLIDEAN-Env3'),\n",
    "\n",
    "    AStar(env_name1, h='smanhattan', name='ASTAR-SManhattan-Env1'),\n",
    "    AStar(env_name2, h='smanhattan', name='ASTAR-SManhattan-Env2'),\n",
    "    AStar(env_name3, h='smanhattan', name='ASTAR-SManhattan-Env3'),\n",
    "\n",
    "    BFS(env_name1, name='BFS-Env1'),\n",
    "    BFS(env_name2, name='BFS-Env2'),\n",
    "    BFS(env_name3, name='BFS-Env3'),\n",
    "\n",
    "    DFS(env_name1, name='DFS-Env1'),\n",
    "    DFS(env_name2, name='DFS-Env2'),\n",
    "    DFS(env_name3, name='DFS-Env3'),\n",
    "\n",
    "    Greedy(env_name1, h='manhattan', name='GREEDY-Manhattan-Env1'),\n",
    "    Greedy(env_name2, h='manhattan', name='GREEDY-Manhattan-Env2'),\n",
    "    Greedy(env_name3, h='manhattan', name='GREEDY-Manhattan-Env3'),\n",
    "\n",
    "    Greedy(env_name1, h='smanhattan', name='GREEDY-SManhattan-Env1'),\n",
    "    Greedy(env_name2, h='smanhattan', name='GREEDY-SManhattan-Env2'),\n",
    "    Greedy(env_name3, h='smanhattan', name='GREEDY-SManhattan-Env3'),\n",
    "\n",
    "    Dijkstra(env_name1, name='DIJKSTRA-Env1'),\n",
    "    Dijkstra(env_name2, name='DIJKSTRA-Env2'),\n",
    "    Dijkstra(env_name3, name='DIJKSTRA-Env3'),\n",
    "\n",
    "    AStar(env_name1, h=NNManhattan, name='ASTAR-NNManhattan-Env1'),\n",
    "    AStar(env_name2, h=NNManhattan, name='ASTAR-NNManhattan-Env2'),\n",
    "    AStar(env_name3, h=NNManhattan, name='ASTAR-NNManhattan-Env3'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a78f94f19bdfce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.121470Z",
     "start_time": "2024-01-25T15:40:18.118756Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "# Define a function to run the algorithms\n",
    "def call(algorithm: Callable, seed_: int, i: int, name: str, local_env_name: str, pbar_: tqdm):\n",
    "    output = tuple([name]) + algorithm(seed_) + tuple([f'{local_env_name}_{i}']) + tuple([seed_])\n",
    "    pbar_.update(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10d87d4dfd81193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.126643Z",
     "start_time": "2024-01-25T15:40:18.123474Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Run the algorithms\n",
    "if not os.path.exists('results_all.csv'):\n",
    "    with tqdm(total=num_of_tries * len(algorithms)) as pbar:\n",
    "        for i in range(num_of_tries):\n",
    "            rand_seed = np.random.randint(0, sys.maxsize)\n",
    "            # insert into df\n",
    "            df = pd.DataFrame(\n",
    "                [call(algorithm=alg, seed_=rand_seed, i=i, name=alg.name, local_env_name=alg.env_name, pbar_=pbar) for alg in\n",
    "                 algorithms],\n",
    "                columns=['Algorithm', 'Solved', 'Path', 'Visited', 'Time', 'Maze_Name', 'Seed'])\n",
    "            # Save for each maze the len of the path and the visited cells\n",
    "            df['Path_Length'] = df['Path'].apply(lambda x: len(x))\n",
    "            df['Visited_Length'] = df['Visited'].apply(lambda x: len(x))\n",
    "            df = df.reset_index(drop=True)\n",
    "    \n",
    "            if df_final.empty:\n",
    "                df_final = df\n",
    "            else:\n",
    "                df_final = pd.concat([df_final, df])\n",
    "    df_final.to_csv('results_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd9b416d340207",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### We computed the results of each algorithm (A*, Greedy, Dijkstra, BFS, DFS) <br> with all the heuristics and pseudo heuristics for A* and Greedy. <br> We also created a Scoring System for the Assessment phase.\n",
    "### Scoring System (Assessment): Defined as the ratio between the path length and the visited cells length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60e9f1eccb828c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.466970Z",
     "start_time": "2024-01-25T15:40:18.125046Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a scoring system\n",
    "df_final = pd.read_csv('results_all.csv', index_col=0)\n",
    "df_final.reset_index(drop=True, inplace=True)   \n",
    "# Convert the string to list of tuples \n",
    "# Remove [ and ] at the beginning and the end\n",
    "df_final['Path'] = df_final['Path'].apply(lambda x: x[1:-1])\n",
    "df_final['Path'] = df_final['Path'].apply(lambda x: list(eval(x)))\n",
    "\n",
    "df_final['Solution_Score'] = df_final['Path'].apply(lambda x: sum(abs(int(x[coord][0]) - int(x[coord + 1][0])) + abs(int(x[coord][1]) - int(x[coord + 1][1])) for coord in range(len(x) - 1)))\n",
    "df_final['Solution_Score'] = 1 - df_final['Solution_Score']/ max(df_final['Solution_Score'])\n",
    "df_final['Solution_Score'] = df_final['Solution_Score'].apply(lambda x: round(x, 3))\n",
    "df_final['Path_Score'] = df_final['Path_Length']/df_final['Visited_Length']\n",
    "\n",
    "df_final = df_final[['Algorithm', 'Time', 'Visited_Length', 'Path_Length', 'Path_Score', 'Solution_Score']]\n",
    "df_final = df_final.groupby('Algorithm').agg({'Time': ['mean', 'std'], 'Visited_Length': ['mean', 'std'], 'Path_Length': ['mean', 'std'], 'Path_Score': ['mean', 'std'], 'Solution_Score': ['mean', 'std']})\n",
    "df_final.columns = ['_'.join(col) for col in df_final.columns.values]\n",
    "df_final = df_final.reset_index()\n",
    "df_final.sort_values(by=['Solution_Score_mean'], ascending=False, inplace=True)\n",
    "df_final.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a3e8d18afae5b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Results\n",
    "Drumroll, please! The moment of truth has arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1364e86aa92a742d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.473011Z",
     "start_time": "2024-01-25T15:40:18.468608Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_maze_large = df_final[df_final['Algorithm'].str.contains('Env1')].sort_values(by=['Path_Score_mean'], ascending=False)\n",
    "results_maze_medium = df_final[df_final['Algorithm'].str.contains('Env2')].sort_values(by=['Path_Score_mean'], ascending=False)\n",
    "results_maze_small = df_final[df_final['Algorithm'].str.contains('Env3')].sort_values(by=['Path_Score_mean'], ascending=False)\n",
    "results_maze_large.reset_index(drop=True, inplace=True)\n",
    "results_maze_medium.reset_index(drop=True, inplace=True)\n",
    "results_maze_small.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10bcbe8c94b2ca99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.485046Z",
     "start_time": "2024-01-25T15:40:18.474192Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(results_maze_large[['Algorithm', 'Time_mean', 'Visited_Length_mean', 'Path_Length_mean', 'Path_Score_mean']].head(4))\n",
    "# print(results_maze_medium[['Algorithm', 'Time_mean', 'Visited_Length_mean', 'Path_Length_mean', 'Path_Score_mean']].head(4))\n",
    "# print(results_maze_small[['Algorithm', 'Time_mean', 'Visited_Length_mean', 'Path_Length_mean', 'Path_Score_mean']].head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136bdff",
   "metadata": {},
   "source": [
    "### Large Maze Results\n",
    "|      Algorithm         | Time_mean | Visited_Length_mean | Path_Length_mean | Path_Score_mean |\n",
    "|------------------------|-----------|---------------------|------------------|------------------|\n",
    "| GREEDY-Manhattan-Env1  | 0.011785  | 122.03              | 77.94            | 0.686225         |\n",
    "| GREEDY-SManhattan-Env1 | 0.012042  | 122.03              | 77.94            | 0.686225         |\n",
    "| ASTAR-NNManhattan-Env1 | 3.822897  | 129.22              | 75.84            | 0.678001         |\n",
    "| ASTAR-SManhattan-Env1  | 0.012503  | 131.24              | 75.84            | 0.664671         |\n",
    "### Medium Maze Results\n",
    "|      Algorithm         | Time_mean | Visited_Length_mean | Path_Length_mean | Path_Score_mean |\n",
    "|------------------------|-----------|---------------------|------------------|------------------|\n",
    "| ASTAR-NNManhattan-Env2 | 1.047521  | 34.13               | 23.47            | 0.772143         |\n",
    "| ASTAR-SManhattan-Env2  | 0.011277  | 34.55               | 23.47            | 0.765570         |\n",
    "| GREEDY-Manhattan-Env2  | 0.011131  | 35.11               | 24.21            | 0.725002         |\n",
    "| GREEDY-SManhattan-Env2 | 0.011163  | 35.11               | 24.21            | 0.725002         |\n",
    "### Small Maze Results\n",
    "|       Algorithm         | Time_mean | Visited_Length_mean | Path_Length_mean | Path_Score_mean |\n",
    "|-------------------------|-----------|---------------------|------------------|------------------|\n",
    "| ASTAR-NNManhattan-Env3  | 0.399369  | 12.00               | 9.63             | 0.878512         |\n",
    "| ASTAR-SManhattan-Env3   | 0.011111  | 11.95               | 9.59             | 0.875009         |\n",
    "| ASTAR-Manhattan-Env3    | 0.011035  | 12.36               | 9.49             | 0.845445         |\n",
    "| ASTAR-EUCLIDEAN-Env3    | 0.011041  | 13.01               | 9.49             | 0.811554         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46ea5fc128ea16",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Our Considerations\n",
    "#### We can see, our Pseudo Heuristic is doing well, being in the top scores almost all the time. <br> It certainly takes time since it's a NN, it will be better to use in batch <br> by giving it all the possible starting points and target points, and then use the output. <br> Also our SManhattan is really good. <br> To be fair we have to say that there are some cases as we can see from the mean scores in which there is a negligible discrepancies, <br> but since our are Pseudo Heuristics we can't obviously guarantee the properties of an Heuristic. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebe8cb095dad5d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Conclusion\n",
    "#### In conclusion we are proud of this project, and the nice results that we got. <br> We have achieved better performance than the state of the art by just using some of our basic skills in the AI field. <br> The pseudo heuristic is interesting, and it took inspiration from some of the papers that we read <br> in which they used a so called Differential Heuristic. <br> Our contribution is to create a Neural Network that approximates the Manhattan distance, and then use it as a heuristic for A* and Greedy. <br> Also we further propose a pseudo heuristic that we called SManhattan, which is the Manhattan distance multiplied by a constant. We would really like to know why the weighting of the Manhattan Distance by a constant was achieving better performance that the normal Heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66f5e13dfc4327",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataset\n",
    "##### We provide with this project a dataset of mazes, that we created with a script that we wrote. We have both images and chars mazes, and we also have the solution for each maze. <br> We created the dataset to train our models. <br> The dataset will not be provided with the project, but you can download it by yourself, it's a really small dataset, so it's not a problem. Read the README\n",
    "### Contribution\n",
    "####  We created basically our heuristic for maze solving, and we wanted to see how it performs. It was a really interesting journey, and we are really proud of our work. <br> We also created a dataset of mazes, and this project itself which is a library, so we can use it in the future for other projects, or <strong>someone else can use it</strong> to create something even better. \n",
    "### Challenges Faced\n",
    "#### We had a lot of challenging moments on trying to use the minihack envirorment... <br> It is not well documented, and it's not easy to use. Also it doesn't provide the Animation that we provided... <br> We took our shot and we created it by ourselves, it was a really nice to see all the algorithms outcome. <br> <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66954f581ea9ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Future Work\n",
    "#### Finally we want to propose the dataset we created as well as the library <br> itself as a starting point for future generations of AIF students that can extend our work and improve it. <br> Our journey doesn't end here. Many tools such as Prolog or algorithms like Monte-Carlo can be applied to this field, <br> also many of the not informed practical algorithms can be implemented. <br> We also wanted to try to implement a new algorithm that we called <strong>QStar</strong> which is a mix <br> between QLearning and A*, but this is another story."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01d0cfe991dfa0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Acknowledgments (Related Works)\n",
    "The course matherials were really useful for this project, obviously.\n",
    "\n",
    "In the field of our project we found some interesting papers that we used as inspiration for our work:\n",
    "- [The Compressed Differential Heuristic](https://cdn.aaai.org/ojs/7823/7823-13-11351-1-2-20201228.pdf)\n",
    "- [Reinforcement Learning with A* and a Deep Heuristic](https://arxiv.org/abs/1811.07745)\n",
    "- [Structured World Representations in Maze-Solving Transformers](https://arxiv.org/abs/2312.02566)\n",
    "\n",
    "Also a project for probably University of Petr Posik\n",
    "- [Robot localization in a maze](https://cw.fel.cvut.cz/b182/_media/courses/ui/tasks/robot_in_maze_description.pdf)\n",
    "\n",
    "We'd like to aknowledge the following resources that contributed to our ideas for this project:\n",
    "- [Minihack Documentation](https://nethackwiki.com/wiki/Minihack)\n",
    "- [Minihack Github](https://github.com/facebookresearch/minihack)\n",
    "- [StackOverflow](https://stackoverflow.com/)\n",
    "- [Github Community](https://github.com/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5b2e9d4a9a3f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Appendix\n",
    "\n",
    "#### We both contributed to the project in the same way. We split some parts of the project such as <br> Paul written some of basic algorithms and the QTable, <br> Stefano contributed to the part of implementing the QLearning agents, the QLSTM and the QNN. <br> We both contributed to this final notebook. <br> Then the utils where actually taken from the course Hands-On, and we modified them to fit our needs. <br> The Animator class was made from scratch, as well as almost all the code in our library and the dataset.\n",
    "\n",
    "#### The project is available on [Github](https://github.com/nextdataAI/aif.git) as well as all the metrics which are not truly representative since we worked many times from the University on the same pc.\n",
    "\n",
    "We loved trying to figure out how some of the arguments seen in the Search Chapter of the course could be applied to the Minihack environment. <br> We also loved trying to figure out how to create a library that integrates part of the algorithms seen, even if we wanted to add more of them. <br> Also we further proposed a new heuristic that we called SManhattan. <br> <br> We are really proud of our work, and we hope that it is actually enjoyable. <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdbee7e488b5d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id='Appendix1'></a>\n",
    "### [1] Technologies Used\n",
    "We harnessed the power of many libraries to create our project.\n",
    "Before we begin, let's make sure you have everything you need to follow along. Here's a list of used libraries:\n",
    "- <font color='red'><strong>numpy</strong></font>\n",
    "- <font color='red'><strong>matplotlib</strong></font>\n",
    "- <font color='red'><strong>minihack</strong></font>\n",
    "- <font color='red'><strong>scipy</strong></font>\n",
    "- <font color='red'><strong>nethack</strong></font>\n",
    "- <font color='red'><strong>nle</strong></font>\n",
    "- <font color='red'><strong>keras</strong></font>\n",
    "- <font color='red'><strong>gym</strong></font>\n",
    "- <font color='red'><strong>tensorflow</strong></font>\n",
    "- <font color='red'><strong>pytorch</strong></font>\n",
    "- <font color='red'><strong>pickle</strong></font>\n",
    "- <font color='red'><strong>Pillow</strong></font>\n",
    "- <font color='red'><strong>imageio</strong></font>\n",
    "- <font color='red'><strong>pandas</strong></font>\n",
    "\n",
    "And here's a list of the other optional libraries:\n",
    "- <font color='gray'><strong>wandb</strong></font> (not necessary, but useful if you want to perform again the experiments)\n",
    "\n",
    "### Uncomment the following cell if you need to install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d7d46888a37a485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.514664Z",
     "start_time": "2024-01-25T15:40:18.493570Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# % pip install wandb\n",
    "# % pip install numpy\n",
    "# % pip install matplotlib\n",
    "# % pip install scipy\n",
    "# % pip install gym\n",
    "# % pip install minihack\n",
    "# % pip install nle\n",
    "# % pip install keras\n",
    "# % pip install tensorflow\n",
    "# % pip install pytorch\n",
    "# % pip install Pillow\n",
    "# % pip install imageio\n",
    "# % pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff7dc7",
   "metadata": {},
   "source": [
    "<a id='Appendix2'></a>\n",
    "## [2] Project Structure\n",
    "Here's a quick overview of the project structure. We've included a brief description of each file to help you navigate:\n",
    "- <font><strong>nextdataAI</strong></font> The root folder of the project:\n",
    "    - <strong>algorithms</strong> This folder contains all the algorithms that we implemented <br>\n",
    "        <em>Algorithm.py</em> Is the superclass of all algorithms, which creates the env, sets the seed so that all are working on the same maze, and also contains the method to run the algorithm. \n",
    "        - Standard:\n",
    "            - <em>AStart</em>, <em>Greedy</em>, <em>Random</em>, <em>Genetic</em>, <em>Dijkstra</em>, <em>BFS (in FS)</em>, <em>DFS (in FS)\n",
    "        - Not Standard\n",
    "            - <em>QLSTM</em>, <em>QNN</em>, <em>QLearning</em> \n",
    "    - <strong>heuristics</strong> This folder contains all the heuristics that we implemented for the A* algorithm and also for Greedy <br>\n",
    "        <em>Heuristic.py</em> Is the superclass of all heuristics \n",
    "        - <em>Manhattan</em>, <em>Euclidean</em>, <em>SManhattan (later we'll explain this one)</em>, <em>Chebysev</em>\n",
    "    - <strong>pseudo_heuristics</strong> This folder contains all the so called by us pseudo heuristics that we implemented for the A* algorithm and also for Greedy, this part of our real contribution to the \"field\"\n",
    "        <em>PseudoHeuristic.py</em> Is the superclass of all pseudo heuristics\n",
    "        - <em> CNN & LSTM <em> are pseudo heuristic that uses a CNN or an LSTM to predict the next action, <br> takes the whole map pixels as input and it has to return the distance from the goal (spoiler: both doesn't work well, but we din't won't to waste time on it)\n",
    "        - <em> NN <em> Same as CNN and LSTM but it takes the chars map, and still doesn't work well\n",
    "        - <em> NNHeuristic <em> <strong>THIS</strong> is the pseudo heuristic that uses a NN which we trained to approximate the Manhattan distance, <br> it takes only the starting and ending position as input and it returns the distance between them. <br> (It works really well, too much, outperforming in most cases all the other heuristics improving the performance of AStar by a lot)\n",
    "    - <strong>QLearning</strong> This folder contains all the Reinforcement Learning basics that we implemented\n",
    "    - <em>AnimateGif.py</em> This class is used to create the gif of the maze solving process\n",
    "    - <em>HeuristicUtils.py & utils.py</em> Just utils used by many of our algorithms\n",
    "- <font><strong>data</strong></font> The folder that contains all the data, with a dedicated dataset class for reading the files, that we used for our experiments with NNs approaches (generated by us)\n",
    "- <font><strong>Papers</strong></font> The folder that contains some papers that we used as inspiration for our work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b71fd",
   "metadata": {},
   "source": [
    "<a id='comparison1'> </a>\n",
    "# [3] Comparison Between: A* (Manhattan, Euclidean, Chebysev), Greedy (Manhattan, Euclidean), BFS, DFS, Dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bac572e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.515689Z",
     "start_time": "2024-01-25T15:40:18.497626Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:| \n",
       "| A* <br> Manhattan  | 0.265 | 49 | 27 | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | 0.147  | 51 | 27 | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n",
       "| BFS              | 0.111 | 65 | 27 | ![BFS](TestsAnimations/BFS.gif) | Dijkstra         | 0.103 | 65 | 27 | ![Dijkstra](TestsAnimations/Dijkstra.gif) |\n",
       "| DFS              | 0.108 | 96 | 27 | ![DFS](TestsAnimations/DFS.gif) | Greedy <br> Manhattan | 0.13 | 39 | 28 | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | \n",
       "| Greedy <br> Euclidean | 0.117 | 38 | 28 | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) | A* <br> Chebysev | 0.11 | 52 | 27 | ![AStarChebysev](TestsAnimations/AStarChebysev.gif) |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "took = {key: round(results[key][-1], 3) for key in results.keys()}\n",
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:| \n",
    "| A* <br> Manhattan  | {took['AStarManhattan']} | {len(results['AStarManhattan'][-2])} | {len(results['AStarManhattan'][-3])} | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | {took['AStarEuclidean']}  | {len(results['AStarEuclidean'][-2])} | {len(results['AStarEuclidean'][-3])} | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n",
    "| BFS              | {took['BFS']} | {len(results['BFS'][-2])} | {len(results['BFS'][-3])} | ![BFS](TestsAnimations/BFS.gif) | Dijkstra         | {took['Dijkstra']} | {len(results['Dijkstra'][-2])} | {len(results['Dijkstra'][-3])} | ![Dijkstra](TestsAnimations/Dijkstra.gif) |\n",
    "| DFS              | {took['DFS']} | {len(results['DFS'][-2])} | {len(results['DFS'][-3])} | ![DFS](TestsAnimations/DFS.gif) | Greedy <br> Manhattan | {took['GreedyManhattan']} | {len(results['GreedyManhattan'][-2])} | {len(results['GreedyManhattan'][-3])} | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | \n",
    "| Greedy <br> Euclidean | {took['GreedyEuclidean']} | {len(results['GreedyEuclidean'][-2])} | {len(results['GreedyEuclidean'][-3])} | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) | A* <br> Chebysev | {took['AStarChebysev']} | {len(results['AStarChebysev'][-2])} | {len(results['AStarChebysev'][-3])} | ![AStarChebysev](TestsAnimations/AStarChebysev.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0051adc",
   "metadata": {},
   "source": [
    "#### Nice, we can clearly see in <font color=\"b6b529\"><strong>Yellow</strong></font> the visited cells, in <font color=\"1b54c7\"><strong>Blue</strong></font> the path found by the algorithm. <br> <strong>Also in the table we can clearly see the time taken by the algorithm, the number of visited cells and the path it found. </strong><br> We can clearly see that in small mazes, the Greedy algorithm is the best one, but we'll later how A* will be really improved by our contribution. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5408d",
   "metadata": {},
   "source": [
    "<a id='comparison2'></a>\n",
    "# [4] QTable Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba4076db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.516328Z",
     "start_time": "2024-01-25T15:40:18.501202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | \n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
       "| QTable          | 0.668 | 71 | 71 | ![QTable](TestsAnimations/QTable.gif) |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | \n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| QTable          | {took['QTable']} | {len(results['QTable'][-2])} | {len(results['QTable'][-3])} | ![QTable](TestsAnimations/QTable.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5bcf7",
   "metadata": {},
   "source": [
    "<a id='comparison3'></a>\n",
    "# [5] QNN and QLSTM Results 9x9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491ff3c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.516892Z",
     "start_time": "2024-01-25T15:40:18.504601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:| \n",
       "| QNN              | 18.192 | 11 | 11 | ![QNN](TestsAnimations/QNN.gif) | QLSTM | 154.46 | 18 | 18 | ![QLSTM](TestsAnimations/QLSTM.gif) |\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'QNN' in results.keys() and 'QLSTM' in results.keys():\n",
    "    try:    \n",
    "        text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:| \n",
    "| QNN              | {took['QNN']} | {len(results['QNN'][-2])} | {len(results['QNN'][-3])} | ![QNN](TestsAnimations/QNN.gif) | QLSTM | {took['QLSTM']} | {len(results['QLSTM'][-2])} | {len(results['QLSTM'][-3])} | ![QLSTM](TestsAnimations/QLSTM.gif) |\n",
    "        '''\n",
    "        display_markdown(text, raw=True)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef1436",
   "metadata": {},
   "source": [
    "<a id='comparison4'></a>\n",
    "# [6] A* and Greedy with NNPseudoHeuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a5b9528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.559894Z",
     "start_time": "2024-01-25T15:40:18.507678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
       "| A* NNHeuristic| 1.474 | 37 | 27 | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy <br> NNHeuristic | 2.89 | 39 | 28 | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* NNHeuristic| {took['AStarNNHeuristic']} | {len(results['AStarNNHeuristic'][-2])} | {len(results['AStarNNHeuristic'][-3])} | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy <br> NNHeuristic | {took['GreedyNNHeuristic']} | {len(results['GreedyNNHeuristic'][-2])} | {len(results['GreedyNNHeuristic'][-3])} | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e54f9",
   "metadata": {},
   "source": [
    "<a id='comparison5'></a>\n",
    "# [7] A* (NNPseudoHeuristic, Manhattan, Euclidean), <br> Greedy (NNPseudoHeuristic, Manhattan, Euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce1ed8a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.634241Z",
     "start_time": "2024-01-25T15:40:18.511869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
       "| A* <br> NNHeuristic| 1.474 | 37 | 27 | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy <br> NNHeuristic | 2.89 | 39 | 28 | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n",
       "| A* <br> Manhattan  | 0.265 | 49 | 27 | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | 0.147  | 51 | 27 | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n",
       "| Greedy <br> Manhattan | 0.13 | 39 | 28 | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | Greedy <br> Euclidean | 0.117 | 38 | 28 | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> NNHeuristic| {took['AStarNNHeuristic']} | {len(results['AStarNNHeuristic'][-2])} | {len(results['AStarNNHeuristic'][-3])} | ![AStarNNHeuristic](TestsAnimations/AStarNNHeuristic.gif) | Greedy <br> NNHeuristic | {took['GreedyNNHeuristic']} | {len(results['GreedyNNHeuristic'][-2])} | {len(results['GreedyNNHeuristic'][-3])} | ![GreedyNNHeuristic](TestsAnimations/GreedyNNHeuristic.gif) |\n",
    "| A* <br> Manhattan  | {took['AStarManhattan']} | {len(results['AStarManhattan'][-2])} | {len(results['AStarManhattan'][-3])} | ![AStarManhattan](TestsAnimations/AStarManhattan.gif) | A* <br> Euclidean  | {took['AStarEuclidean']}  | {len(results['AStarEuclidean'][-2])} | {len(results['AStarEuclidean'][-3])} | ![AStarEuclidean](TestsAnimations/AStarEuclidean.gif) |\n",
    "| Greedy <br> Manhattan | {took['GreedyManhattan']} | {len(results['GreedyManhattan'][-2])} | {len(results['GreedyManhattan'][-3])} | ![GreedyManhattan](TestsAnimations/GreedyManhattan.gif) | Greedy <br> Euclidean | {took['GreedyEuclidean']} | {len(results['GreedyEuclidean'][-2])} | {len(results['GreedyEuclidean'][-3])} | ![GreedyEuclidean](TestsAnimations/GreedyEuclidean.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3be60",
   "metadata": {},
   "source": [
    "<a id='comparison6'></a>\n",
    "# [8] Comparison between A* (NNPseudoHeuristic, Manhattan, Euclidean) Large Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "452754f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.668840Z",
     "start_time": "2024-01-25T15:40:18.515151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
       "| A* <br> NNHeuristic| 6.424 | 200 | 107 | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) | A* <br> Manhattan  | 0.112 | 287 | 107 | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
       "| A* <br> Euclidean  | 0.219  | 288 | 107 | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | _ | _ | _ | _ | _ |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> NNHeuristic| {took['AStarNNHeuristicLarge']} | {len(results['AStarNNHeuristicLarge'][-2])} | {len(results['AStarNNHeuristicLarge'][-3])} | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) | A* <br> Manhattan  | {took['AStarManhattanLarge']} | {len(results['AStarManhattanLarge'][-2])} | {len(results['AStarManhattanLarge'][-3])} | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
    "| A* <br> Euclidean  | {took['AStarEuclideanLarge']}  | {len(results['AStarEuclideanLarge'][-2])} | {len(results['AStarEuclideanLarge'][-3])} | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | _ | _ | _ | _ | _ |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ddff6f",
   "metadata": {},
   "source": [
    "<a id='comparison7'></a>\n",
    "# [9] Comparison between A* (NNPseudoHeuristic, Manhattan, Euclidean, SManhattan) Large Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3313c9ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:40:18.710084Z",
     "start_time": "2024-01-25T15:40:18.519186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
       "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
       "| A* <br> SManhattan| 0.108 | 201 | 107 | ![AStarSManhattanLarge](TestsAnimations/AStarSManhattanLarge.gif) | A* <br> Manhattan  | 0.112 | 287 | 107 | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
       "| A* <br> Euclidean  | 0.219  | 288 | 107 | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | A* <br> NNHeuristic| 6.424 | 200 | 107 | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f'''\n",
    "| Algorithm        | Time  | Visited | Path |                                                    Image | Algorithm        | Time  | Visited | Path |                                                    Image |\n",
    "|:-----------------|------:|--------:|--------:|---------------------------------------------------------:|------------------|------:|--------:|--------:|---------------------------------------------------------:|\n",
    "| A* <br> SManhattan| {took['AStarSManhattanLarge']} | {len(results['AStarSManhattanLarge'][-2])} | {len(results['AStarSManhattanLarge'][-3])} | ![AStarSManhattanLarge](TestsAnimations/AStarSManhattanLarge.gif) | A* <br> Manhattan  | {took['AStarManhattanLarge']} | {len(results['AStarManhattanLarge'][-2])} | {len(results['AStarManhattanLarge'][-3])} | ![AStarManhattanLarge](TestsAnimations/AStarManhattanLarge.gif) |\n",
    "| A* <br> Euclidean  | {took['AStarEuclideanLarge']}  | {len(results['AStarEuclideanLarge'][-2])} | {len(results['AStarEuclideanLarge'][-3])} | ![AStarEuclideanLarge](TestsAnimations/AStarEuclideanLarge.gif) | A* <br> NNHeuristic| {took['AStarNNHeuristicLarge']} | {len(results['AStarNNHeuristicLarge'][-2])} | {len(results['AStarNNHeuristicLarge'][-3])} | ![AStarNNHeuristicLarge](TestsAnimations/AStarNNHeuristicLarge.gif) |\n",
    "'''\n",
    "display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d9d5cb",
   "metadata": {},
   "source": [
    "<a id='allres1'></a>\n",
    "# [10] All the results on the mazes in the previous cells of the Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Time</th>\n",
       "      <th>Visited</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AStarManhattan</td>\n",
       "      <td>0.265486</td>\n",
       "      <td>49</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AStarEuclidean</td>\n",
       "      <td>0.146662</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AStarChebysev</td>\n",
       "      <td>0.110143</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFS</td>\n",
       "      <td>0.107685</td>\n",
       "      <td>96</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFS</td>\n",
       "      <td>0.110553</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dijkstra</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GreedyManhattan</td>\n",
       "      <td>0.129911</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GreedyEuclidean</td>\n",
       "      <td>0.116978</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QTable</td>\n",
       "      <td>0.668030</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AStarNNHeuristic</td>\n",
       "      <td>1.473836</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GreedyNNHeuristic</td>\n",
       "      <td>2.889513</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AStarNNHeuristicLarge</td>\n",
       "      <td>6.423930</td>\n",
       "      <td>200</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AStarManhattanLarge</td>\n",
       "      <td>0.111732</td>\n",
       "      <td>287</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AStarEuclideanLarge</td>\n",
       "      <td>0.219195</td>\n",
       "      <td>288</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AStarSManhattanLarge</td>\n",
       "      <td>0.108122</td>\n",
       "      <td>201</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Genetic</td>\n",
       "      <td>377.514986</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>QNN</td>\n",
       "      <td>18.191521</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>QLSTM</td>\n",
       "      <td>154.459532</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm        Time  Visited  Path\n",
       "0          AStarManhattan    0.265486       49    27\n",
       "1          AStarEuclidean    0.146662       51    27\n",
       "2           AStarChebysev    0.110143       52    27\n",
       "3                     DFS    0.107685       96    27\n",
       "4                     BFS    0.110553       65    27\n",
       "5                Dijkstra    0.103459       65    27\n",
       "6         GreedyManhattan    0.129911       39    28\n",
       "7         GreedyEuclidean    0.116978       38    28\n",
       "8                  QTable    0.668030       71    71\n",
       "9        AStarNNHeuristic    1.473836       37    27\n",
       "10      GreedyNNHeuristic    2.889513       39    28\n",
       "11  AStarNNHeuristicLarge    6.423930      200   107\n",
       "12    AStarManhattanLarge    0.111732      287   107\n",
       "13    AStarEuclideanLarge    0.219195      288   107\n",
       "14   AStarSManhattanLarge    0.108122      201   107\n",
       "15                Genetic  377.514986     1001  1001\n",
       "16                    QNN   18.191521       11    11\n",
       "17                  QLSTM  154.459532       18    18"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(results.keys())\n",
    "df_data = []\n",
    "print('\\nAll Results:')\n",
    "for kw in keys:\n",
    "    try:\n",
    "        # print(f'Algorithm: {kw} Time:{results[kw][-1]} Visited:{len(results[kw][-2])} Path:{len(results[kw][-3])}', end='\\n')\n",
    "       df_data.append([kw, results[kw][-1], len(results[kw][-2]), len(results[kw][-3])])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(kw)\n",
    "        continue\n",
    "    \n",
    "df_data = pd.DataFrame(df_data, columns=['Algorithm', 'Time', 'Visited', 'Path'])\n",
    "df_data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
